import os
import typing
import abc
import json
import inspect
import logging
import collections
import math

import collections.abc as abstract_collections

from datetime import datetime
from datetime import date
from datetime import time

import pandas
import numpy

from dateutil.parser import parse as parse_date

import dmod.metrics as metrics
import dmod.metrics.metric as metric_functions
import dmod.metrics.scoring as scoring

from .. import util

logging.basicConfig(
    filename='evaluation.log',
    level=logging.getLevelName(os.environ.get('METRIC_LOG_LEVEL', os.environ.get("DEFAULT_LOG_LEVEL", "DEBUG"))),
    format=os.environ.get("LOG_FORMAT", "%(asctime)s,%(msecs)d %(levelname)s: %(message)s"),
    datefmt=os.environ.get("LOG_DATEFMT", "%H:%M:%S")
)


def get_specifications(base_specification: typing.Type = None) -> typing.List[typing.Type]:
    """
    Returns:
        All implemented specifications
    """
    if base_specification is None:
        base_specification = Specification

    subclasses = [
        cls
        for cls in base_specification.__subclasses__()
        if not inspect.isabstract(cls)
    ]

    abstract_subclasses = [
        cls
        for cls in base_specification.__subclasses__()
        if inspect.isabstract(cls)
    ]

    for abstract_class in abstract_subclasses:
        subclasses.extend(get_specifications(abstract_class))

    return subclasses



def is_a_value(o) -> bool:
    """
    Whether the passed object is a value and not some method or module or something

    Args:
        o:
            The object to be tested
    Returns:
        Whether the passed object is a value and not some method or module or something
    """
    # This will exclude methods, code, stuff like __get__, __set__, __add__, async objects, etc
    return not (
        inspect.iscode(o)
        or inspect.isdatadescriptor(o)
        or inspect.ismethoddescriptor(o)
        or inspect.ismemberdescriptor(o)
        or inspect.ismodule(o)
        or inspect.isgenerator(o)
        or inspect.isgeneratorfunction(o)
        or inspect.ismethod(o)
        or inspect.isawaitable(o)
        or inspect.isabstract(o)
    )


def value_matches_parameter_type(value, parameter: typing.Union[inspect.Parameter, typing.Type]) -> bool:
    """
    Checks to see if the given value matches that of the passed in parameter

    Since a parameter without an annotation is interpreted as `typing.Any`, `True` is returned if not type is indicated

    Args:
        value: The value to check
        parameter: The parameter to check

    Returns:
        Whether the given value conforms to the parameter
    """
    if isinstance(parameter, inspect.Parameter) and parameter.annotation == parameter.empty:
        return True

    if isinstance(parameter, inspect.Parameter):
        parameter = parameter.annotation

    is_typing_class = isinstance(parameter, typing._GenericAlias)
    is_union = is_typing_class and isinstance(parameter, typing._UnionGenericAlias)
    parameter_is_number = util.type_is_number(parameter)

    if parameter_is_number:
        return util.value_is_number(value)
    if is_union:
        return True in [
            value_matches_parameter_type(value, t)
            for t in typing.get_args(parameter)
        ]
    if is_typing_class:
        return isinstance(value, typing.__dict__[parameter._name])

    try:
        return isinstance(value, parameter)
    except TypeError:
        return False


def convert_value(value: typing.Any, parameter: typing.Union[inspect.Parameter, typing.Type]) -> typing.Any:
    """
    Attempts to convert a given value to the type expected by the parameter

    Args:
        value: The value to convert
        parameter: The function parameter that may or may not dictate what to cast the value as

    Returns:
        An attempted conversion if a parameter type is given; just the original value otherwise
    """
    if isinstance(parameter, inspect.Parameter):
        parameter_type: typing.Type = None if parameter.annotation == parameter.empty else parameter.annotation
    else:
        parameter_type: typing.Union[typing.Type, typing.Type[Specification]] = parameter

    if parameter_type is None:
        return value

    if parameter_type in util.get_subclasses(Specification):
        return parameter_type.create(value)
    if isinstance(value, str) and util.value_is_number(value) and util.type_is_number(parameter_type):
        return float(value)
    elif isinstance(value, bytes) and util.value_is_number(value) and util.type_is_number(parameter_type):
        return float(value.decode())
    elif not (isinstance(value, str) or isinstance(value, bytes)) and isinstance(value, typing.Sequence):
        expected_type = typing.get_args(parameter_type)
        converted_values = [
            convert_value(member, expected_type[0])
            for member in value
        ]
        return converted_values

    return value


def create_class_instance(cls, data, decoder: json.JSONDecoder = None):
    """
    Dynamically creates a class based on the type of class and the given parameters

    Args:
        cls: The type of class to construct
        data: The data that provides construction arguments
        decoder: An optional json decoder that will help deserialize any json inputs

    Returns:
        An instance of the given `cls`
    """
    # If the object is already the intended class, you're done!
    if isinstance(data, cls):
        return data

    # If the object is some sort of buffer, go ahead and read in the data for later interpretation
    if hasattr(data, "read"):
        data = data.read()

    # If the data is a series of bytes, convert that into a string for later interpretation
    if isinstance(data, bytes):
        data: str = data.decode()

    # If the data is a string AND it looks like it can be valid json, try to convert it into a dictionary
    if isinstance(data, str):
        stripped_data = data.strip()
        is_possible_json_object = stripped_data.startswith("{") and stripped_data.endswith("}")
        is_possible_json_array = stripped_data.startswith("[") and stripped_data.endswith("]")
        if is_possible_json_object or is_possible_json_array:
            try:
                data: typing.Dict[str, typing.Any] = json.loads(data, cls=decoder)
            except json.JSONDecodeError:
                # If the string can't be interpreted as JSON, try to interpret in another way later.
                logging.error(
                        "Tried to interpret string data as json, but it wasn't valid. "
                        "Continuing with attempted parsing."
                )

    # If data is a list of lists or objects, send each back to this function and return a list instead of a single value
    if not isinstance(data, str) and isinstance(data, typing.Sequence):
        return [
            create_class_instance(cls, input_value, decoder)
            for input_value in data
            if is_a_value(input_value)
        ]

    # If it doesn't have some sort of '__getitem__' or is a string, we can assume that this is a singular value
    # and we can just send that as a parameter
    if isinstance(data, str) or not hasattr(data, "__getitem__"):
        return cls(data)

    constructor_signature: inspect.Signature = inspect.signature(cls)

    arguments: typing.Dict[str, typing.Any] = dict()

    required_parameters = [
        parameter
        for parameter in constructor_signature.parameters.values()
        if parameter.default == parameter.empty
           and parameter.kind != parameter.VAR_KEYWORD
           and parameter.kind != parameter.VAR_POSITIONAL
    ]

    missing_parameters = list()

    if hasattr(data, "__getitem__") and not isinstance(data, typing.Sequence):
        for parameter in constructor_signature.parameters.values():  # type: inspect.Parameter
            if parameter.kind == parameter.VAR_KEYWORD:
                continue

            try:
                value = data[parameter.name]

                value = convert_value(value, parameter)

                arguments[parameter.name] = value
            except KeyError:
                if parameter not in required_parameters:
                    arguments[parameter.name] = parameter.default
                else:
                    missing_parameters.append(str(parameter))

        if missing_parameters:
            raise ValueError(f"'{cls} can't be constructed - arguments are missing: {', '.join(missing_parameters)}")

        if 'properties' not in arguments or arguments['properties'] is None:
            arguments['properties'] = dict()

        arguments['properties'].update({
            key: value
            for key, value in data.items()
            if key not in arguments
        })

        return cls(**arguments)

    raise ValueError(f"Type '{type(data)}' cannot be read as JSON")


class Specification(abc.ABC):
    """
    Instructions for how different aspects of an evaluation should work
    """
    __slots__ = ['__properties']

    @classmethod
    def create(cls, data: typing.Union[str, dict, typing.IO, bytes, typing.Sequence], decoder: json.JSONDecoder = None):
        """
        A factory for the given specification

        Args:
            data: Parameters used to instantiate the specification
            decoder: an optional json decoder used to deserialize the specification

        Returns:
            An instance of the specified specification class
        """
        instance = create_class_instance(cls, data, decoder)

        messages = list()

        if isinstance(instance, typing.Sequence):
            for member in instance:
                messages.extend(member.validate())
        else:
            validation_messages = instance.validate()
            if validation_messages:
                messages.extend(validation_messages)

        if messages:
            message = f"{cls.__name__} could not be properly created:{os.linesep}{os.linesep.join(messages)}"
            raise ValueError(message)

        return instance

    @abc.abstractmethod
    def validate(self) -> typing.Sequence[str]:
        """
        Returns:
            Any messages indicating a problem with the specification
        """
        pass

    @abc.abstractmethod
    def to_dict(self) -> typing.Dict[str, typing.Any]:
        """
        Returns:
            The specification converted into a dictionary
        """
        pass

    def to_json(self, buffer: typing.IO = None) -> typing.Optional[typing.Union[str, typing.IO]]:
        """
        Either converts the instance into a json string or writes that json string into the given buffer

        Args:
            buffer: An optional buffer to feed the json into

        Returns:
            The updated buffer if a buffer is passed, otherwise the json string
        """
        dict_representation = self.to_dict()

        if buffer:
            json.dump(dict_representation, buffer, indent=4)
            return buffer

        return json.dumps(dict_representation, indent=4)

    def __init__(self, properties: typing.Union[typing.Dict[str, typing.Any], str, bytes] = None, **kwargs):
        if properties is None:
            properties = dict()
        elif isinstance(properties, str):
            properties = json.loads(properties)
        elif isinstance(properties, bytes):
            properties = json.loads(properties.decode())

        properties.update(kwargs)

        self.__properties = properties

    @property
    def properties(self) -> typing.Dict[str, typing.Any]:
        """
        Returns:
            A dictionary of arbitrary properties passed into the specification that don't match direct members
        """
        return self.__properties.copy()

    def get(self, key: str, default: typing.Any = None) -> typing.Any:
        """
        Retrieve either the property with the given key or the default

        Args:
            key: The key to the value to retrieve
            default: The value to return if the key is not present

        Returns:
            The property value matching the key if present, `None` otherwise
        """
        return self.__properties.get(key, default)

    def __getitem__(self, key: str) -> typing.Any:
        return self.__properties[key]

    def __contains__(self, key: str) -> bool:
        return key in self.__properties

    def __repr__(self) -> str:
        return str({
            key.replace("__", ""): getattr(self, key)
            for key in self.__slots__
        })


class UnitDefinition(Specification):
    """
    A definition of what a measurement unit is or where to find it
    """
    def validate(self) -> typing.Sequence[str]:
        messages = list()

        if not self.__value and not self.__path and not self.__field:
            messages.append("Unit definition is missing a field, a path, and a value; no unit data will be found.")

        fields_and_values = {
            "value": bool(self.__value),
            "path": bool(self.__path),
            "field": bool(self.__field)
        }

        marked_fields = [
            name
            for name, exists in fields_and_values.items()
            if exists
        ]

        if len(marked_fields) > 1:
            messages.append(f"Values for {' and '.join(marked_fields)} have all been set - only one is valid")

        return messages

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        data = dict()

        if self.__field:
            data["field"] = self.__field
        elif self.__path:
            data['path'] = self.__path
        elif self.__value:
            data['value'] = self.__value

        return data

    __slots__ = ["__field", "__path", "__value"]

    def __init__(
            self,
            value: typing.Union[str, bytes] = None,
            field: str = None,
            path: typing.Union[str, typing.Sequence[str]] = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super(UnitDefinition, self).__init__(properties, **kwargs)

        self.__field = field

        path_starts_at_root = False

        if isinstance(path, str):
            path_starts_at_root = path.startswith("/")
            self.__path = path.split("/")
        else:
            self.__path = path

        if path_starts_at_root:
            self.__path.insert(0, "$")

        if isinstance(value, bytes):
            value = value.decode()

        self.__value = value

    @property
    def field(self) -> typing.Optional[str]:
        return self.__field

    @property
    def path(self) -> typing.Optional[typing.Sequence[str]]:
        return self.__path

    @property
    def value(self) -> typing.Optional[str]:
        return self.__value

    def __str__(self):
        if self.__field:
            return self.__field

        return ".".join(self.__path)


class ThresholdDefinition(Specification):
    """
    A definition of a single threshold, the field that it comes from, and its significance
    """
    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        return {
            "name": self.__name,
            "field": self.__field,
            "unit": self.__unit.to_dict(),
            "weight": self.__weight,
            "properties": self.__properties
        }

    __slots__ = ["__name", "__field", "__weight", "__unit"]

    def __init__(
            self,
            name: typing.Union[str, bytes],
            field: typing.Union[str, bytes, typing.Sequence[str]],
            weight: typing.Union[str, float],
            unit: typing.Union[UnitDefinition, str, dict],
            properties: typing.Union[typing.Dict[str, typing.Any], str] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        self.__name = name.decode() if isinstance(name, bytes) else name

        if isinstance(field, bytes):
            field = field.decode()

        if isinstance(field, str):
            self.__field = field.split("/")
        else:
            self.__field = field

        self.__weight = weight

        if isinstance(unit, str):
            unit = UnitDefinition(value=unit)
        elif isinstance(unit, dict):
            unit = UnitDefinition.create(unit)

        self.__unit = unit

    @property
    def name(self) -> str:
        """
        Returns:
            The name of the threshold. This should appear as the name of the threshold in the output and doesn't
            have to match the field it came from
        """
        return self.__name

    @property
    def field(self) -> typing.Sequence[str]:
        """
        Returns:
            The name of the field in the datasource where these values are supposed to come from
        """
        return self.__field

    @property
    def weight(self) -> float:
        """
        Returns:
            The significance of the threshold
        """
        return self.__weight

    @property
    def unit(self) -> UnitDefinition:
        return self.__unit

    def __str__(self) -> str:
        return f"{self.__name}, weighing {self.__weight}, from the '{self.__field}' field."

    def __repr__(self) -> str:
        return str(self.to_dict())


class BackendSpecification(Specification):
    """
    A specification of how data should be loaded
    """

    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "backend_type": self.__backend_type,
            "address": self.__address,
            "data_format": self.__format
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__backend_type", "__address", "__format"]

    def __init__(
            self,
            backend_type: str,
            data_format: str,
            address: str = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        self.__backend_type = backend_type
        self.__format = data_format
        self.__address = address

    @property
    def type(self) -> str:
        """
        The type of backend that should be used
        """
        return self.__backend_type

    @property
    def format(self) -> str:
        """
        The type of data to be interpretted

        A single backend type may have more than one format. A `file` may be json, csv, netcdf, etc
        """
        return self.__format

    @property
    def address(self) -> typing.Optional[str]:
        """
        Where the data for the backend to interpret lies
        """
        return self.__address

    def __str__(self) -> str:
        description = self.__backend_type
        if self.__address:
            description += f": {self.__address}"
        else:
            description += f"=> {self.__format}"

        return description


class LoaderSpecification(Specification, abc.ABC):
    """
    Represents a class that uses a backend to load data
    """
    __slots__ = ['_backend']

    @property
    @abc.abstractmethod
    def backend(self) -> BackendSpecification:
        ...


class FieldMappingSpecification(Specification):
    """
    Details on how a field should be aliased
    """

    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "field": self.__field,
            "map_type": self.__map_type,
            "value": self.__value
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__field", "__map_type", "__value"]

    def __init__(
            self,
            field: str,
            map_type: str,
            value: str,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)
        self.__field = field
        self.__map_type = map_type
        self.__value = value

    @property
    def field(self) -> str:
        """
        The field to be aliased
        """
        return self.__field

    @property
    def map_type(self) -> str:
        """
        Where the field to be aliased lies (is it a key? Is it a dictionary value? Is it a column?)
        """
        return self.__map_type

    @property
    def value(self) -> str:
        """
        What the field should end up being called
        """
        return self.__value

    def __str__(self) -> str:
        return f"{self.__map_type}: {self.__field} comes from {self.__value}"


class AssociatedField(Specification):
    """
    A specification for additional data that should accompany selected data
    (retrieved measurements? Also get their dates)
    """
    def validate(self) -> typing.Sequence[str]:
        messages = list()
        if self.__name is None or self.__name == '':
            messages.append(f"An index is missing a proper name")

        return messages

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "name": self.__name,
            "datatype": self.__datatype,
            "path": self.__path
        }

        if self.__properties:
            dictionary['properties'] = self.__properties.copy()

        return dictionary

    __slots__ = ["__name", "__datatype", "__path"]

    def __init__(
            self,
            name: str,
            path: typing.Union[str, typing.Sequence[str]] = None,
            datatype: typing.Union[str, typing.Sequence[str]] = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        self.__name = name

        path_starts_at_root = False

        if path is None:
            self.__path = [name]
        elif isinstance(path, str):
            path_starts_at_root = path.startswith("/")
            self.__path = path.split("/")
        else:
            self.__path = path

        if path_starts_at_root:
            self.__path.insert(0, "$")

        self.__datatype = datatype.lower() if datatype else None

    @property
    def name(self) -> str:
        return self.__name

    @property
    def path(self) -> typing.Sequence[str]:
        """
        The path to the data in the source
        """
        return self.__path

    @property
    def datatype(self) -> str:
        """
        The type that the value should be parsed as

        A date may come in as a string - `"2022-01-22T15:33:14-0600"`, for example, but we need to actually use that
        as a date and time. If this isn't converted, it won't match up to `"2022-01-22T16:33:14-0500"`
        """
        return self.__datatype

    def to_datatype(self, value):
        """
        Attempt to convert the given value to the required datatype

        Args:
            value: The value to convert

        Returns:
            The converted value, if specified
        """
        if not self.__datatype or value is None:
            return value

        datatype = self.__datatype.lower()

        if datatype in ("datetime", "date", "time"):
            raw_datetime = parse_date(value)

            if datatype == 'date':
                return raw_datetime.date()
            elif datatype == 'time':
                return raw_datetime.time()

            return raw_datetime

        if datatype in ('float', 'double', 'number') and str(value).isnumeric():
            return float(value)

        if datatype in ('int', 'integer') and str(value).isdigit():
            return int(value)

        if datatype in ('str', 'string', 'word', 'id', 'identifier'):
            return str(value)

        if datatype in ('day',):
            return util.Day(value)

        return value

    def get_concrete_datatype(self) -> typing.Type:
        datatype = self.__datatype.lower()
        if datatype == 'datetime':
            return datetime
        if datatype == 'date':
            return date
        if datatype == 'time':
            return time
        if datatype in ('float', 'double', 'number'):
            return float
        if datatype in ('int', 'integer'):
            return int
        if datatype in ('day',):
            return util.Day

        return str

    def __str__(self):
        return f"{self.__name}: {self.__datatype}"


class ValueSelector(Specification):
    """
    Instructions for how to retrieve values from a data source
    """
    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "where": self.__where,
            "path": self.__path,
            "origin": self.__origin,
            "datatype": self.__datatype,
            "name": self.__name
        }

        if self.__associated_fields:
            dictionary['associated_fields'] = [
                field.to_dict()
                for field in self.__associated_fields
            ]

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__name", "__where", "__path", "__associated_fields", "__datatype", "__origin"]

    def __init__(
            self,
            name: str,
            where: str,
            origin: typing.Union[str, bytes, typing.Sequence[str]] = None,
            path: typing.Union[str, bytes, typing.Sequence[str]] = None,
            associated_fields: typing.Sequence[AssociatedField] = None,
            datatype: str = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        origin_starts_at_root = False

        if isinstance(origin, str):
            origin_starts_at_root = origin.startswith("/")
            origin = origin.split("/")
        elif isinstance(origin, bytes):
            origin = origin.decode()
            origin_starts_at_root = origin.startswith("/")
            origin = origin.split("/")
        elif not origin:
            origin = ["$"]

        if origin_starts_at_root and origin[0] != '$':
            origin.insert(0, "$")

        if origin:
            origin = [
                part
                for part in origin
                if bool(part)
            ]

        path_starts_at_root = False
        if isinstance(path, str):
            path_starts_at_root = path.startswith("/")
            path = path.split("/")
        elif isinstance(path, bytes):
            path = path.decode()
            path_starts_at_root = path.startswith("/")
            path = path.split("/")

        if path_starts_at_root:
            path.insert(0, '$')

        if path:
            path = [
                part
                for part in path
                if bool(part)
            ]

        self.__where = where
        self.__origin = origin
        self.__path = path
        self.__name = name

        if associated_fields is None:
            associated_fields = list()

        self.__associated_fields = associated_fields
        self.__datatype = datatype.lower() if datatype is not None else None

    def get_column_types(self) -> typing.Dict[str, typing.Union[typing.Dict[str, typing.Any], typing.List[str]]]:
        """
        Gets a list of columns and their required parsing types

        This should only be necessary for constructors that require extra notification for fields, such as pandas

        Returns:
            A dictionary mapping columns to their parsing types and an optional list of columns that are dates
        """
        column_options = dict()

        if self.__datatype in ["datetime", "date"]:
            column_options['parse_dates'] = [self.__name]
        else:
            dtype = util.type_name_to_dtype(self.__datatype)

            if dtype is not None:
                column_options['dtype'] = {self.__name: dtype}

        for index in self.associated_fields:
            if index.datatype in ["datetime", "date"]:
                if 'parse_dates' not in column_options:
                    column_options['parse_dates'] = list()

                if index.name not in column_options['parse_dates']:
                    column_options['parse_dates'].append(index.name)
            else:
                dtype = util.type_name_to_dtype(index.datatype)

                if dtype is not None:
                    if 'dtype' not in column_options:
                        column_options['dtype'] = dict()

                    column_options['dtype'][index.name] = dtype

        return column_options

    def to_datatype(self, value):
        """
        Attempt to convert the given value to the required datatype

        Args:
            value: The value to convert

        Returns:
            The converted value, if specified
        """
        if not self.__datatype:
            return value

        datatype = self.__datatype.lower()

        if datatype in ("datetime", "date", "time"):
            raw_datetime = parse_date(value)

            if datatype == 'date':
                return raw_datetime.date()
            elif datatype == 'time':
                return raw_datetime.time()

            return raw_datetime

        if datatype in ('str', 'string', 'word', 'id', 'identifier'):
            return str(value)

        if datatype in ('int', 'integer') and str(value).isdigit():
            return int(value)

        if datatype in ('float', 'double', 'number') and util.str_is_float(value):
            return float(value)

        if datatype in ('day',):
            return util.Day(value)

        return value

    @property
    def where(self) -> str:
        """
        Where the value may be found (Dict key? Dict value? Column?)
        """
        return self.__where

    @property
    def origin(self) -> typing.Optional[typing.Sequence[str]]:
        """
        The path from which to look

        The value should be `""` or `"/"` if searching from the root.
        """
        return self.__origin

    @property
    def path(self) -> typing.Optional[typing.Sequence[str]]:
        """
        The path from which to look from the origin
        """
        return self.__path

    @property
    def name(self) -> str:
        return self.__name

    @property
    def associated_fields(self) -> typing.Sequence[AssociatedField]:
        """
        Additional values to retrieve with selected values
        """
        return self.__associated_fields

    def __str__(self) -> str:
        description = f"{self.__name} => {self.__where}"

        if self.__path:
            description += f": {self.__path.join(os.linesep)}"

        if self.__associated_fields:
            description += f", indexed by [{','.join(self.__associated_fields)}]"

        return description


class ThresholdApplicationRules(Specification):
    """
    Added rules for how thresholds should be applied
    """

    __slots__ = ['__threshold_field', '__observation_field', '__prediction_field']

    def validate(self) -> typing.Sequence[str]:
        messages = list()

        return messages

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        pass

    def __init__(
            self,
            threshold_field: AssociatedField,
            observation_field: AssociatedField = None,
            prediction_field: AssociatedField = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties=properties, **kwargs)
        self.__threshold_field = threshold_field
        self.__observation_field = observation_field
        self.__prediction_field = prediction_field

    @property
    def threshold_field(self) -> AssociatedField:
        return self.__threshold_field

    @property
    def observation_field(self) -> typing.Optional[AssociatedField]:
        return self.__observation_field

    @property
    def prediction_field(self) -> typing.Optional[AssociatedField]:
        return self.__prediction_field

    def __repr__(self):
        return str(self.to_dict())

    def __str__(self):
        representation = f"The threshold built around {self.__threshold_field}"

        if self.__observation_field and self.__prediction_field:
            representation += f" is applied to the observations aligned by {self.__observation_field} " \
                              f"and the predictions aligned by {self.__prediction_field}"
        elif self.__observation_field:
            representation += f" is applied to the observations aligned by {self.__observation_field}"
        else:
            representation += f" is applied to the predictions aligned by {self.__prediction_field}"

        return representation


class LocationSpecification(Specification):
    """
    A specification for where location data should be found
    """
    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "identify": self.__identify,
            "from_field": self.__from_field,
            "pattern": self.__pattern,
            "ids": self.__ids
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__identify", "__from_field", "__pattern", "__ids"]

    def __init__(
            self,
            identify: bool = None,
            from_field: str = None,
            pattern: typing.Union[str, typing.Sequence[str]] = None,
            ids: typing.List[str] = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        if isinstance(ids, str):
            ids = list(ids)
        elif ids is None:
            ids = list()

        if identify and not (from_field or pattern or ids):
            raise ValueError(
                    "A from_field, a pattern, or a list of ids are required if locations are supposed to be identified"
            )

        if pattern and not from_field:
            raise ValueError(
                    "A from_field is required if a location is to be found from a pattern"
            )
        elif from_field and ids:
            raise ValueError(
                    "Locations may be discovered from a static list or a field, but not both"
            )

        if from_field or ids:
            identify = True

        if identify is None:
            identify = False

        if from_field != 'filename' and isinstance(pattern, str):
            pattern_starts_at_root = pattern.startswith("/")
            pattern = pattern.split("/")

            if pattern_starts_at_root:
                pattern.insert(0, "$")

        self.__identify = identify
        self.__from_field = from_field
        self.__pattern = pattern
        self.__ids = ids

    @property
    def ids(self) -> typing.List[str]:
        """
        A list of specific ids to use for locations
        """
        return self.__ids

    @property
    def from_field(self) -> str:
        """
        A field from which to retrieve location names from a source

        This would be where you'd indicate that the location name came from the filename, for example
        """
        return self.__from_field

    @property
    def pattern(self) -> typing.Sequence[str]:
        """
        An optional regex for how to retrieve the name

        If the data are in files like `cat-67.json`, a regex like `^[A-Za-z]+-\d+` would indicate that the name
        should be interpreted as `cat-67` and not `cat-67.json`
        """
        return self.__pattern

    @property
    def should_identify(self) -> bool:
        """
        Whether locations should even be attempted to be identified

        Location identification isn't really necessary for single location evaluations, for example
        """
        return self.__identify

    def __str__(self) -> str:
        if self.__from_field and self.__pattern:
            return f"Identify locations matching '{self.__pattern}' from the '{self.__from_field}'"
        elif self.__from_field:
            return f"Identify locations from the '{self.__from_field}'"
        elif self.__ids:
            return f"Use the ids with the names: {', '.join(self.__ids)}"
        return "Don't identify locations"


class DataSourceSpecification(LoaderSpecification):
    """
    Specification for where to get the actual data for evaluation
    """
    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "name": self.__name,
            "value_selectors": [selector.to_dict() for selector in self.__value_selectors],
            "backend": self._backend.to_dict(),
            "locations": self.__locations.to_dict(),
            "field_mapping": [mapping.to_dict() for mapping in self.__field_mapping],
            "unit": self.__unit.to_dict(),
            "x_axis": self.__x_axis
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__name", "__value_field", "__locations", "__field_mapping", "__value_selectors", "__unit", "__x_axis"]

    def __init__(
            self,
            value_field: str,
            backend: BackendSpecification,
            value_selectors: typing.Sequence[ValueSelector],
            unit: UnitDefinition,
            name: str = None,
            x_axis: str = None,
            locations: LocationSpecification = None,
            field_mapping: typing.List[FieldMappingSpecification] = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)
        self._backend = backend
        self.__name = name if name else value_field
        self.__value_field = value_field
        self.__locations = locations if locations else LocationSpecification(identify=False)
        self.__field_mapping = field_mapping if field_mapping else list()
        self.__value_selectors = value_selectors
        self.__unit = unit
        self.__x_axis = x_axis or "value_date"

    @property
    def name(self) -> str:
        return self.__name

    @property
    def value_field(self) -> str:
        return self.__value_field

    @property
    def backend(self) -> BackendSpecification:
        return self._backend

    @property
    def locations(self) -> LocationSpecification:
        return self.__locations

    @property
    def field_mapping(self) -> typing.List[FieldMappingSpecification]:
        return [mapping for mapping in self.__field_mapping]

    @property
    def value_selectors(self) -> typing.Sequence[ValueSelector]:
        return [selector for selector in self.__value_selectors]

    @property
    def field_names(self) -> typing.Sequence[str]:
        names: typing.List[str] = list()

        return names

    @property
    def unit(self) -> UnitDefinition:
        return self.__unit

    @property
    def x_axis(self) -> str:
        return self.__x_axis

    def get_column_options(self) -> typing.Dict[str, typing.Union[typing.Dict[str, typing.Any], typing.List[str]]]:
        """
        Gets options that may be required for loading data into a table

        Returns:

        """
        options = dict()

        for selector in self.__value_selectors:
            selector_options = selector.get_column_types()

            for key, value in selector_options.items():
                if key not in options:
                    options[key] = value
                elif isinstance(options[key], dict):
                    options[key].update(value)
                elif util.is_arraytype(options[key]):
                    for entry in value:
                        if entry not in options[key]:
                            options[key].append(entry)

        return options

    def __str__(self) -> str:
        return f"{self.__name} ({str(self._backend)})"


class CrosswalkSpecification(LoaderSpecification):
    """
    Specifies how locations in the observations should be linked to locations in the predictions
    """
    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "backend": self._backend.to_dict(),
            "entity_path": self.entity_path,
            "field": self.__field.to_dict(),
            "prediction_field_name": self.__prediction_field_name,
            "observation_field_name": self.__observation_field_name
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ['__origin', "__field", '__prediction_field_name', '__observation_field_name']

    def __init__(
            self,
            backend: BackendSpecification,
            field: ValueSelector,
            observation_field_name: str,
            prediction_field_name: str = None,
            origin: typing.Union[str, typing.Sequence[str]] = None,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)
        if origin is None:
            origin = "$"

        self._backend = backend
        self.__origin = origin.split(".") if isinstance(origin, str) else origin
        self.__field = field
        self.__observation_field_name = observation_field_name
        self.__prediction_field_name = prediction_field_name if prediction_field_name else observation_field_name

    @property
    def backend(self) -> BackendSpecification:
        return self._backend

    @property
    def field(self) -> ValueSelector:
        return self.__field

    @property
    def prediction_field_name(self) -> str:
        return self.__prediction_field_name

    @property
    def observation_field_name(self) -> str:
        return self.__observation_field_name

    @property
    def entity_path(self) -> typing.Sequence[str]:
        return self.__origin

    def __str__(self) -> str:
        return f"Crosswalk from: {self._backend} with observed values from {self.__field}"


class MetricSpecification(Specification):
    def validate(self) -> typing.Sequence[str]:
        return list()

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "name": self.__name,
            "weight": self.__weight
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__name", "__weight"]

    def __init__(
            self,
            name: str,
            weight: float,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        self.__name = name
        self.__weight = weight

    @property
    def name(self) -> str:
        return self.__name

    @property
    def weight(self) -> float:
        return self.__weight

    def __str__(self) -> str:
        description = f"{self.__name} = {self.__weight}"

        if self.__properties:
            description += f" ({str(self.__properties)}"")"

        return description


class SchemeSpecification(Specification):
    def validate(self) -> typing.Sequence[str]:
        messages = list()

        for metric in self.__metrics:
            messages.extend(metric.validate())

        return messages

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "metrics": [metric.to_dict() for metric in self.__metrics]
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__metrics"]

    def __init__(
            self,
            metrics: typing.Sequence[MetricSpecification],
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        self.__metrics = metrics

    @property
    def metric_functions(self) -> typing.Sequence[MetricSpecification]:
        return [metric for metric in self.__metrics]

    @property
    def total_weight(self) -> float:
        return sum([metric.weight for metric in self.__metrics])

    def generate_scheme(self) -> metrics.ScoringScheme:
        generated_metrics: typing.List[metrics.Metric] = [
            metric_functions.get_metric(metric.name, metric.weight)
            for metric in self.__metrics
        ]
        return metrics.ScoringScheme(
                generated_metrics
        )

    def __str__(self) -> str:
        details = {
            "metrics": [str(metric) for metric in self.__metrics],
        }

        if self.__properties:
            details["properties"] = self.__properties

        return str(details)


class ThresholdSpecification(LoaderSpecification):
    def validate(self) -> typing.Sequence[str]:
        messages = list()

        messages.extend(self._backend.validate())
        messages.extend(self.__locations.validate())

        if len(self.__definitions) == 0:
            messages.append("There are no threshold definitions defined within a threshold specification")

        for definition in self.__definitions:
            messages.extend(definition.validate())

        return messages

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "backend": self._backend.to_dict(),
            "locations": self.__locations.to_dict(),
            "origin": self.__origin,
            "definitions": [definition.to_dict() for definition in self.__definitions],
            "application_rules": self.__application_rules.to_dict()
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__locations", "__definitions", "__origin", "__application_rules"]

    def __init__(
            self,
            backend: BackendSpecification,
            definitions: typing.Sequence[ThresholdDefinition],
            locations: LocationSpecification = None,
            application_rules: ThresholdApplicationRules = None,
            properties: typing.Dict[str, typing.Any] = None,
            origin: typing.Union[str, typing.Sequence[str]] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        self._backend = backend
        self.__definitions = definitions
        self.__locations = locations
        self.__application_rules = application_rules

        origin_starts_at_root = False

        if isinstance(origin, str):
            origin_starts_at_root = origin.startswith("/")
            origin = origin.split("/")
        elif isinstance(origin, bytes):
            origin = origin.decode()
            origin_starts_at_root = origin.startswith("/")
            origin = origin.split("/")
        elif not origin:
            origin = ["$"]

        if origin_starts_at_root and origin[0] != '$':
            origin.insert(0, "$")

        self.__origin = origin

    @property
    def backend(self) -> BackendSpecification:
        return self._backend

    @property
    def definitions(self) -> typing.Sequence[ThresholdDefinition]:
        return self.__definitions

    @property
    def locations(self) -> typing.Optional[LocationSpecification]:
        return self.__locations

    @property
    def origin(self) -> typing.Optional[typing.Sequence[str]]:
        return self.__origin

    @property
    def application_rules(self) -> ThresholdApplicationRules:
        return self.__application_rules

    @property
    def total_weight(self) -> float:
        """
        The weight of all defined thresholds
        """
        return sum([definition.weight for definition in self.__definitions])

    def __contains__(self, definition_name) -> bool:
        matching_definitions = [
            definition
            for definition in self.__definitions
            if definition.name.lower() == definition_name.lower()
        ]

        if matching_definitions:
            return True

        matching_definitions = [
            definition
            for definition in self.__definitions
            if definition.field[-1].lower() == definition_name.lower()
        ]

        if matching_definitions:
            return True

        return False

    def __getitem__(self, definition_name) -> typing.Optional[ThresholdDefinition]:
        matching_definitions = [
            definition
            for definition in self.__definitions
            if definition.name.lower() == definition_name.lower()
        ]

        if matching_definitions:
            return matching_definitions[0]

        matching_definitions = [
            definition
            for definition in self.__definitions
            if definition.field[-1].lower() == definition_name.lower()
        ]

        if matching_definitions:
            return matching_definitions[0]

        return None


class EvaluationSpecification(Specification):
    def validate(self) -> typing.Sequence[str]:
        messages = list()

        for observation_source in self.__observations:
            messages.extend(observation_source.validate())

        for prediction_source in self.__predictions:
            messages.extend(prediction_source.validate())

        for crosswalk_source in self.__crosswalks:
            messages.extend(crosswalk_source.validate())

        for threshold_source in self.__thresholds:
            messages.extend(threshold_source.validate())

        messages.extend(self.__scheme.validate())

        return messages

    def to_dict(self) -> typing.Dict[str, typing.Any]:
        dictionary = {
            "observations": [specification.to_dict() for specification in self.__observations],
            "predictions": [specification.to_dict() for specification in self.__predictions],
            "crosswalks": [crosswalk.to_dict() for crosswalk in self.__crosswalks],
            "thresholds": [thresholds.to_dict() for thresholds in self.__thresholds],
            "scheme": self.__scheme.to_dict()
        }

        if self.__properties:
            dictionary['properties'] = self.__properties

        return dictionary

    __slots__ = ["__observations", "__predictions", "__crosswalks", "__thresholds", "__scheme"]

    def __init__(
            self,
            observations: typing.Sequence[DataSourceSpecification],
            predictions: typing.Sequence[DataSourceSpecification],
            crosswalks: typing.Sequence[CrosswalkSpecification],
            thresholds: typing.Sequence[ThresholdSpecification],
            scheme: SchemeSpecification,
            properties: typing.Dict[str, typing.Any] = None,
            **kwargs
    ):
        super().__init__(properties, **kwargs)

        self.__observations = observations
        self.__predictions = predictions
        self.__crosswalks = crosswalks
        self.__thresholds = thresholds
        self.__scheme = scheme

    @property
    def observations(self) -> typing.Sequence[DataSourceSpecification]:
        """
        All specifications for where observation data should come from
        """
        return self.__observations

    @property
    def predictions(self) -> typing.Sequence[DataSourceSpecification]:
        """
        All specifications for where prediction data should come from
        """
        return self.__predictions

    @property
    def crosswalks(self) -> typing.Sequence[CrosswalkSpecification]:
        """
        All specifcations for where to get data detailing how to tie observation locations to prediction locations
        """
        return self.__crosswalks

    @property
    def scheme(self) -> SchemeSpecification:
        """
        The specification for what metrics to apply and how they relate to one another
        """
        return self.__scheme

    @property
    def thresholds(self) -> typing.Sequence[ThresholdSpecification]:
        """
        All specifications for what thresholds should be applied to observations and predictions
        """
        return self.__thresholds

    @property
    def weight_per_location(self) -> float:
        """
        The maximum value each location can have
        """
        total_threshold_weight = sum([threshold.total_weight for threshold in self.__thresholds])

        return total_threshold_weight + self.__scheme.total_weight



class EvaluationResults:
    def __init__(
            self,
            instructions: EvaluationSpecification,
            raw_results: typing.Dict[typing.Tuple[str, str], metrics.MetricResults]
    ):
        self._instructions = instructions
        self._original_results = raw_results.copy()
        self._location_map: typing.Dict[str, typing.Dict[str, metrics.MetricResults]] = collections.defaultdict(dict)

        self._total = sum([
            metric_result.total
            for metric_result in raw_results.values()
            if not numpy.isnan(metric_result.total)
        ])

        for (observed_location, predicted_location), metric_result in self._original_results.items():
            self._location_map[observed_location][predicted_location] = metric_result
            self._location_map[predicted_location][observed_location] = metric_result

    def __getitem__(self, item: str) -> typing.Dict[str, metrics.MetricResults]:
        return self._location_map[item]

    def __iter__(self):
        return iter(self._original_results.items())

    def __len__(self):
        return len(self._original_results)

    def __str__(self):
        locations_in_calculations = [
            f"{observation_location} vs. {prediction_location}"
            for (observation_location, prediction_location) in self._original_results.keys()
        ]
        return f"{', '.join(locations_in_calculations)}: {self._total}"

    def to_frames(self, include_metadata: bool = None) -> typing.Dict[str, pandas.DataFrame]:
        """
        Converts two or more dimensional results into a DataFrame

        NOTE: Scalar values, such as the final results, will not be included

        Returns:
            A DataFrame describing the results of all scores, across all thresholds, across all location pairings
        """
        if include_metadata is None:
            include_metadata = False

        frames: typing.Dict[str, pandas.DataFrame] = dict()

        for (observation_location, prediction_location), results in self._original_results.items():
            results_frame = results.to_dataframe(include_metadata=include_metadata)
            results_frame['observed_location'] = observation_location
            results_frame['predicted_location'] = prediction_location
            frames[f"{observation_location} vs. {prediction_location}"] = results_frame

        return frames

    def to_dict(self, include_specification: bool = None) -> typing.Dict[str, typing.Any]:
        """
        Converts the results into a dictionary

        Args:
            include_specification: Whether to include the specifications for how to conduct the evaluation

        Returns:
            The evaluation results in the form of a nested dictionary
        """
        data = dict()

        data['total'] = self._total
        data['grade'] = "{:.2f}%".format(self.grade)
        data['max_possible_total'] = self.max_possible_value
        data['mean'] = self.mean
        data['median'] = self.median
        data['standard_deviation'] = self.standard_deviation

        data['results'] = list()

        include_specification = bool(include_specification)

        if include_specification:
            data['specification'] = self._instructions.to_dict()

        included_metrics: typing.List[dict] = list()

        for result in self._original_results.values():
            for _, scores in result:
                for score in scores:
                    if not [metric for metric in included_metrics if metric['name'] == score.metric.name]:
                        included_metrics.append({
                            "name": score.metric.name,
                            "weight": score.metric.weight,
                            "description": score.metric.get_descriptions()
                        })

        data['metrics'] = included_metrics

        for (observation_location, prediction_location), results in self._original_results.items():
            result_data = {
                "observation_location": observation_location,
                "prediction_location": prediction_location,
                'total': results.total,
                "results": list()
            }

            for score_threshold, scores in results:  # type: metrics.Threshold, typing.List[metrics.Score]
                threshold_results: typing.Dict[str, typing.Any] = {
                    "name": score_threshold.name,
                    "weight": score_threshold.weight,
                    "scores": list(),
                }

                if isinstance(score_threshold.value, pandas.DataFrame) \
                        and len(score_threshold.value) == 1 \
                        and len(score_threshold.value.keys()) == 1:
                    first_column = [key for key in score_threshold.value.keys()][0]
                    threshold_value = float(score_threshold.value[first_column].values[0])
                elif isinstance(score_threshold.value, pandas.Series) and len(score_threshold.value) == 1:
                    threshold_value = float(score_threshold.value.values[0])
                elif isinstance(score_threshold.value, typing.Sequence) and len(score_threshold.value) == 1:
                    threshold_value = float(score_threshold.value[0])
                elif isinstance(score_threshold.value, (pandas.DataFrame, pandas.Series, typing.Sequence)):
                    threshold_value = "varying"
                else:
                    threshold_value = float(score_threshold.value)

                threshold_results['threshold_value'] = threshold_value

                threshold_total = 0
                maximum_value = 0

                for score in scores:
                    threshold_total += 0 if numpy.isnan(score.scaled_value) else score.scaled_value
                    maximum_value += score.metric.weight
                    score_data = {
                        "metric": score.metric.name,
                        "weight": score.metric.weight,
                        "value": None if numpy.isnan(score.value) else score.value,
                        "scaled_value": None if numpy.isnan(score.scaled_value) else score.scaled_value,
                        "sample_size": None if numpy.isnan(score.sample_size) else score.sample_size
                    }

                    threshold_results['scores'].append(score_data)

                total_factor = threshold_total / maximum_value
                threshold_results['result'] = threshold_total
                threshold_results['maximum_result'] = maximum_value
                threshold_results['scaled_result'] = score_threshold.weight * total_factor
                result_data['results'].append(threshold_results)

            data['results'].append(result_data)

        return data

    @property
    def value(self) -> float:
        """
        The resulting value for the evaluation over all location pairings
        """
        return self._total

    @property
    def instructions(self) -> EvaluationSpecification:
        """
        The specifications that told the system how to evaluate
        """
        return self._instructions

    @property
    def max_possible_value(self) -> float:
        """
        The highest possible value that can be achieved with the given instructions
        """
        total_threshold_weight = sum([
            evaluation_threshold.total_weight
            for evaluation_threshold in self._instructions.thresholds
        ])

        result_count = len(self._original_results)

        return float(result_count * total_threshold_weight)

    @property
    def max_effective_value(self) -> float:
        if self.max_possible_value in (0, None, numpy.nan, math.nan):
            return 0.0

        # The difference between this and the max possible value is that the realistic value discounts scores where
        # nothing happened so as not to penalize the model for correctly not really doing anything
        max_realistic_value = 0

        for metric_results in self._original_results.values():
            for scores in metric_results.populated_thresholds.values():
                for score in scores:
                    max_realistic_value += score.metric.weight

        return max_realistic_value

    @property
    def grade(self, as_percentage: bool = True) -> float:
        """
        The total weighted grade percentage result across all location pairings. Scales from 0.0 to 100.0
        """
        if self.max_possible_value in (0, None, numpy.nan, math.nan):
            return 0.0

        if as_percentage is None:
            as_percentage = True

        weight_of_all_locations = sum([
            result.weight
            for result in self._original_results.values()
        ])
        """The total weight of all locations"""

        target_calculated_grade = 0
        """The calculated grade sum that indicates an absolutely perfect verification across all locations"""

        total_calculated_grade = 0
        """The sum of calculated grade values across all location results"""

        for location_results in self._original_results.values():
            location_percentage = location_results.weight / weight_of_all_locations
            """
            The percentage of how this set of values affects the whole
            
            If this location's weight is greater than another's, this location's grade will have a greater 
            affect on the total
            """

            # Find the sum of all weights of the thresholds containing all metrics, multiply that value by the
            # percentage that these results affect the whole, then add them to the target value
            #
            # Metric weights don't need to be considered here because they are already scaled against the
            # threshold weights
            target_calculated_grade += sum(
                [threshold.weight for threshold in location_results.populated_thresholds]
            ) * location_percentage

            # Find the total of this location by summing the quotient of the sum of all scaled score values
            # divided by the sum of the target score values, multiplied by the weight of its threshold
            # across all thresholds
            #
            # If you have a threshold with a weight of 10 with a result of 0.78 and a threshold with a weight of 5
            # with a result of 0.76, you end up with a sum of 11.1 with the value of the first threshold having a
            # greater effect on the sum. This yields an effective grade of 11.1/15, or 0.74. That 0.74 is not recorded
            # here because both components (11.1 and 15) are used later to compute weighted sums used to calculate a
            # weighted score
            #
            #                     (     ∑j scaled value for score(j) in Threshold(i)                           )
            #  scaled total = ∑i  (   -----------------------------------------------  *  Threshold(i) Weight  )
            #  (for location)     (     ∑j    score(j) weight in Threshold(i)                                  )
            #
            scaled_total = sum([
                (
                        sum([score.scaled_value for score in scores])
                        / sum([score.metric.weight for score in scores])
                ) * threshold.weight
                for threshold, scores in location_results.populated_thresholds.items()
            ])
            """The grade of the results for this location and this location only"""

            # Scale the calculated grade for this location by the percentage that this location affects the whole
            scaled_location_grade = scaled_total * location_percentage

            # Add the scaled grade to the total for the later weighted sum
            total_calculated_grade += scaled_location_grade

        calculated_grade = total_calculated_grade / target_calculated_grade if target_calculated_grade > 0 else 0.0

        if as_percentage:
            # We now have the value calculated and the value we hoped to calculate. Dividing one from the other yields
            # the total grade of the verification. Multiplying that by 100.0 yields the percentage
            calculated_grade *= 100.0

            # Ensure that the percentage calculated fits between the boundaries of the scale
            calculated_grade = max(min(calculated_grade, 100.0), 0)

        return float(calculated_grade)

    @property
    def mean(self) -> float:
        """
        The mean total value across all evaluated location pairings
        """
        return float(numpy.mean(
                [
                    result.total
                    for result in self._original_results.values()
                ]
        ))

    @property
    def median(self) -> float:
        """
        The median total value across all evaluated location pairings
        """
        return float(numpy.median(
                [
                    result.total
                    for result in self._original_results.values()
                ]
        ))

    @property
    def standard_deviation(self) -> float:
        """
        The standard deviation for result values across all location pairings
        """
        return float(numpy.std(
                [
                    result.total
                    for result in self._original_results.values()
                ]
        ))
