To do list:
1. Add memory allocation/check *
2. Put clean_keys() in an if block *
3. Use an if block to choose which resource checking block to use *
4. Clean up logging *
5. Check to see whether any method can be made to return a value
6. Double check the logic in retrieve_job_metadata()
7. Study the key functionality of each method. Test the functionality
8. Read documentation on unittest
9. Make check_runningJobs return a list
10. Rewrite the service_to_host_mapping() function
11. How to check a failed job?
12. Make the reporting functions print/log more useful info
13. It is probably better to test the retrieve_metadata() method within scheduler.py
14. Consider putting all the set up for runJob(), startJobs, and create_service() into setup() *
15. Using @unittest.skip() and @unittest.expectedFailure
16. retrieve_job_metadata() may retrieve old data previously rpushed on to the database. Need to clean up to retrieve fresh data
17. Go inside each method and see how code blocks can be tested. *
------------

I can only see the containers launched on apd-dev1 through "docker service create"
not the containers launched on ucs2 and ucs3

It seems that the "mounts" in services.create in scheduler.py conflicts with the "COPY" command
in /nwm/Dockerfile. "mounts" appear to overwrite everythng.
Need to comment out the two lines "mounts = mounts" in scheduler.py to be able to COPY
Also, the COPY operation seems to preserve the time stamp of the copied file

It seems that build order matters. The following build order produce the correct result.
Note that  the COPY operation preserve the time stamp of the copied file

$ docker build -t 127.0.0.1:5000/nwm-2.0 ./nwm
$ docker build -t 127.0.0.1:5000/mgmt ./scheduler
$ python3 -m unittest discover -v

Unittest and production run changes:
1. scheduler.py: local import
   scheduler.py: from scheduler.utils.clean import clean_keys (~line 785)
   scheduler.py: redis using local host or docker container
2. utils/clean.py: import scheduler.utils.keynamehelper as keynamehelper
3. request.py: local import
4. entry.sh: sudo python3 ...
5. clean_redisKeys()
6. change the Redis client to localhost/Docker container

- Need to comment out startJobs to see queued jobs as currently startJobs empties all jobs in the _jobQ
  idx seems not used in fromRequest() method

- Added code in clean_redisKeys():
        self.redis.flushdb()
        self.redis.flushall()    # Delete all the keys of all the existing databases, not just 
                                 # the currently selected one. This command never fails.

- Check the possibility of cpus_alloc < 0

- Why does it give me errors the first time I run the unit test after the maintainance?
  The errors seeem related to Redis

- Add memory allocation/check

- Put clean_keys() in a if block

- The for loop part of the code in test_14_startJobs is not executed when the last returned cpusList is empty

- When I had a test/ directory in both /apd_common/scui/nwm_service and /apd_common/scui/nwm_service/scheduler,
  the unit test is run twice by "$python3 -m unittest discover" command. Looks like it tries to discover both copies

- I need to comment out the schedule.startJobs() code line AND "def test_15_enqueue(self)" for the _jobQ to give correct count.

- Calling check_generalized_round_robin(), check_availability_and_schedule(), check_single_node_availability() in test_14
  does not seem to register the resource usage in Redis database
  Whereas calling them in test_4, 5, 6 does, why?

- However, this is correctly registered if I print the resources in the scheduler code. Possibly has to do with how the Redis database
  is accessed. Need to investigate whether database is accessed correctly in test_7_print_resource_details().

- I think the test_7_print_resource_details() accesses the resources in test_scheduler.py.

- test_12_fromRequest() increases the _jobQ by once count.

- test_13_runJob() actually start the containers

- test_15_enqueue() inreases the value of _jobQ by one count

- Need to uncomment clean_redisKeys() in setup() to clean up the keys, then comment it out to run without test errors

- Still need to carefully check the retrieve_job_metadata() to ascertain that it works correctly
- It works correctly if all the ckecking resource method are called in test_14_startJobs(). See next item for cause.

- Caution in interpreting the output from "retrieve_job_metadata()" method when "check_generalized_round_robin()" method is used. Even
  though ucs2 & ucs3 may have plenty amout of resources, the job will not be submitted because apd-dev1 has 0 CPU available.

- Note that calling check resource functions directly in unit test does not change _jobQ. There are 3 places in the unit test code
  that change the variable _jobQ: test_12_fromRequest, test_14_startJobs, and test_15_enqueue.

- Why do I have to set up the resources in the unit test code for the retrieve_job_metadata() method to work?
  Resources need to be explicitly set in unit test code to eliminate the following error in test. Possibly this is because resources is
  declared as global in the scheduler.py code:

  File "/apd_common/scui/nwm_service/scheduler/scheduler.py", line 272, in check_availability_and_schedule
    CPUs = int(redis.hget(e_key, "CPUs"))
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'

- It appears that I only need to copy over the "resources". The unit test works by commenting out test_2_create_resources() part.

- One possible approach is to move the global "resources" variable into __init__(), i.e., to make it a class variable?
  The downside is that every time the class is called, the "resources" info is copied, which is a nusance.







